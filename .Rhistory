lwd = 2,
bty = "n") # no box around legend
legend("topright",
legend = c("Mean estimate", "95% CI", "true sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
true_sum_of_Ozone
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 50 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 50 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 10)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
data = data %>% drop_na(Ozone)
# Install packages if you don't have them
install.packages(c("mice", "dplyr"))
library(mice)
library(tidyr)
library(dplyr)
# for reproducibility
set.seed(123)
# Install packages if you don't have them
install.packages(c("mice", "dplyr"))
library(mice)
library(tidyr)
library(dplyr)
# for reproducibility
set.seed(123)
# Use the built-in 'airquality' dataset
data <- airquality
data = data %>% drop_na(Ozone)
true_sum_of_Ozone <- sum(data$Ozone, na.rm = T)
# Our goal is to sum the 'Ozone' column
# Let's see the original data and the original sum (ignoring NAs for now)
cat("Original number of missing Ozone values:", sum(is.na(data$Ozone)), "\n")
cat("Sum of Ozone with original missing values removed:", sum(data$Ozone, na.rm = TRUE), "\n")
# Use the built-in 'airquality' dataset
data <- airquality
data = data %>% drop_na(Ozone)
true_sum_of_Ozone <- sum(data$Ozone, na.rm = T)
# Our goal is to sum the 'Ozone' column
# Let's see the original data and the original sum (ignoring NAs for now)
cat("Original number of missing Ozone values:", sum(is.na(data$Ozone)), "\n")
cat("Sum of Ozone with original missing values removed:", sum(data$Ozone, na.rm = TRUE), "\n")
prop_to_remove <- 0.25
n_ozone_present <- sum(!is.na(data$Ozone))
n_to_remove <- floor(prop_to_remove * n_ozone_present)
# Get the indices of the currently non-missing Ozone values
indices_present <- which(!is.na(data$Ozone))
# Randomly sample from those indices to select which ones to set to NA
indices_to_remove <- sample(indices_present, size = n_to_remove)
# Create a new data frame for our experiment
data_missing <- data
data_missing$Ozone[indices_to_remove] <- NA
cat("Total number of missing Ozone values after removal:", sum(is.na(data_missing$Ozone)), "\n")
cat("Percentage of Ozone data now missing:",
round(sum(is.na(data_missing$Ozone)) / nrow(data_missing) * 100, 2), "%\n")
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 50, method = 'pmm', printFlag = FALSE, seed = 456)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# The best point estimate for the sum is the average of all the sums.
final_point_estimate <- mean(list_of_sums)
# The uncertainty is captured by the standard deviation of these sums.
uncertainty_std_dev <- sd(list_of_sums)
# We create a 95% confidence interval using the quantiles of our distribution.
confidence_interval <- quantile(list_of_sums, probs = c(0.025, 0.975))
# Print the final results
cat("--- Final Results ---\n")
cat("Point Estimate for Total Ozone:", round(final_point_estimate, 2), "\n")
cat("Uncertainty (Standard Deviation of Sums):", round(uncertainty_std_dev, 2), "\n")
cat("95% Confidence Interval for Total Ozone: [",
round(confidence_interval[1], 2), ", ",
round(confidence_interval[2], 2), "]\n")
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 50 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 10)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 50 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 100, method = 'pmm', printFlag = FALSE, seed = 456)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 100, method = 'pmm', printFlag = FALSE)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# The best point estimate for the sum is the average of all the sums.
final_point_estimate <- mean(list_of_sums)
# The uncertainty is captured by the standard deviation of these sums.
uncertainty_std_dev <- sd(list_of_sums)
# We create a 95% confidence interval using the quantiles of our distribution.
confidence_interval <- quantile(list_of_sums, probs = c(0.025, 0.975))
# Print the final results
cat("--- Final Results ---\n")
cat("Point Estimate for Total Ozone:", round(final_point_estimate, 2), "\n")
cat("Uncertainty (Standard Deviation of Sums):", round(uncertainty_std_dev, 2), "\n")
cat("95% Confidence Interval for Total Ozone: [",
round(confidence_interval[1], 2), ", ",
round(confidence_interval[2], 2), "]\n")
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 50 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 100 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
prop_to_remove <- 0.5
n_ozone_present <- sum(!is.na(data$Ozone))
n_to_remove <- floor(prop_to_remove * n_ozone_present)
# Get the indices of the currently non-missing Ozone values
indices_present <- which(!is.na(data$Ozone))
# Randomly sample from those indices to select which ones to set to NA
indices_to_remove <- sample(indices_present, size = n_to_remove)
# Create a new data frame for our experiment
data_missing <- data
data_missing$Ozone[indices_to_remove] <- NA
cat("Total number of missing Ozone values after removal:", sum(is.na(data_missing$Ozone)), "\n")
cat("Percentage of Ozone data now missing:",
round(sum(is.na(data_missing$Ozone)) / nrow(data_missing) * 100, 2), "%\n")
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 100, method = 'pmm', printFlag = FALSE)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# The best point estimate for the sum is the average of all the sums.
final_point_estimate <- mean(list_of_sums)
# The uncertainty is captured by the standard deviation of these sums.
uncertainty_std_dev <- sd(list_of_sums)
# We create a 95% confidence interval using the quantiles of our distribution.
confidence_interval <- quantile(list_of_sums, probs = c(0.025, 0.975))
# Print the final results
cat("--- Final Results ---\n")
cat("Point Estimate for Total Ozone:", round(final_point_estimate, 2), "\n")
cat("Uncertainty (Standard Deviation of Sums):", round(uncertainty_std_dev, 2), "\n")
cat("95% Confidence Interval for Total Ozone: [",
round(confidence_interval[1], 2), ", ",
round(confidence_interval[2], 2), "]\n")
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 100 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# We introduceren willekeurig ontbrekende data in ALLE kolommen.
prop_to_remove <- 0.30 # We verwijderen 30% van de bestaande, niet-NA data per kolom
# Maak een nieuwe data frame voor ons experiment
data_missing <- data
# Loop door elke kolom van de dataset
for (col_name in names(data_missing)) {
# Vind de indices van de waarden die nu aanwezig zijn
indices_present <- which(!is.na(data_missing[[col_name]]))
n_present <- length(indices_present)
# Bepaal hoeveel waarden we gaan verwijderen
n_to_remove <- floor(prop_to_remove * n_present)
# Voer de verwijdering alleen uit als er iets te verwijderen valt
if (n_to_remove > 0) {
# Selecteer willekeurig de indices die we naar NA gaan zetten
indices_to_remove <- sample(indices_present, size = n_to_remove)
# Zet de geselecteerde waarden op NA
data_missing[[col_name]][indices_to_remove] <- NA
}
}
# Toon een overzicht van de ontbrekende data na de verwijdering
cat("Overzicht van ontbrekende waarden (NAs) per kolom na verwijdering:\n")
print(sapply(data_missing, function(x) sum(is.na(x))))
cat("\nTotaal percentage ontbrekende cellen in de dataset:",
round(sum(is.na(data_missing)) / (nrow(data_missing) * ncol(data_missing)) * 100, 2), "%\n")
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 100, method = 'pmm', printFlag = FALSE)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# The best point estimate for the sum is the average of all the sums.
final_point_estimate <- mean(list_of_sums)
# The uncertainty is captured by the standard deviation of these sums.
uncertainty_std_dev <- sd(list_of_sums)
# We create a 95% confidence interval using the quantiles of our distribution.
confidence_interval <- quantile(list_of_sums, probs = c(0.025, 0.975))
# Print the final results
cat("--- Final Results ---\n")
cat("Point Estimate for Total Ozone:", round(final_point_estimate, 2), "\n")
cat("Uncertainty (Standard Deviation of Sums):", round(uncertainty_std_dev, 2), "\n")
cat("95% Confidence Interval for Total Ozone: [",
round(confidence_interval[1], 2), ", ",
round(confidence_interval[2], 2), "]\n")
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 100 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# We introduceren willekeurig ontbrekende data in ALLE kolommen.
prop_to_remove <- 0.5 # We verwijderen 30% van de bestaande, niet-NA data per kolom
# Maak een nieuwe data frame voor ons experiment
data_missing <- data
# Loop door elke kolom van de dataset
for (col_name in names(data_missing)) {
# Vind de indices van de waarden die nu aanwezig zijn
indices_present <- which(!is.na(data_missing[[col_name]]))
n_present <- length(indices_present)
# Bepaal hoeveel waarden we gaan verwijderen
n_to_remove <- floor(prop_to_remove * n_present)
# Voer de verwijdering alleen uit als er iets te verwijderen valt
if (n_to_remove > 0) {
# Selecteer willekeurig de indices die we naar NA gaan zetten
indices_to_remove <- sample(indices_present, size = n_to_remove)
# Zet de geselecteerde waarden op NA
data_missing[[col_name]][indices_to_remove] <- NA
}
}
# Toon een overzicht van de ontbrekende data na de verwijdering
cat("Overzicht van ontbrekende waarden (NAs) per kolom na verwijdering:\n")
print(sapply(data_missing, function(x) sum(is.na(x))))
cat("\nTotaal percentage ontbrekende cellen in de dataset:",
round(sum(is.na(data_missing)) / (nrow(data_missing) * ncol(data_missing)) * 100, 2), "%\n")
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 100, method = 'pmm', printFlag = FALSE)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# The best point estimate for the sum is the average of all the sums.
final_point_estimate <- mean(list_of_sums)
# The uncertainty is captured by the standard deviation of these sums.
uncertainty_std_dev <- sd(list_of_sums)
# We create a 95% confidence interval using the quantiles of our distribution.
confidence_interval <- quantile(list_of_sums, probs = c(0.025, 0.975))
# Print the final results
cat("--- Final Results ---\n")
cat("Point Estimate for Total Ozone:", round(final_point_estimate, 2), "\n")
cat("Uncertainty (Standard Deviation of Sums):", round(uncertainty_std_dev, 2), "\n")
cat("95% Confidence Interval for Total Ozone: [",
round(confidence_interval[1], 2), ", ",
round(confidence_interval[2], 2), "]\n")
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 100 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
# We introduceren willekeurig ontbrekende data in ALLE kolommen.
prop_to_remove <- 0.90 # We verwijderen 30% van de bestaande, niet-NA data per kolom
# Maak een nieuwe data frame voor ons experiment
data_missing <- data
# Loop door elke kolom van de dataset
for (col_name in names(data_missing)) {
# Vind de indices van de waarden die nu aanwezig zijn
indices_present <- which(!is.na(data_missing[[col_name]]))
n_present <- length(indices_present)
# Bepaal hoeveel waarden we gaan verwijderen
n_to_remove <- floor(prop_to_remove * n_present)
# Voer de verwijdering alleen uit als er iets te verwijderen valt
if (n_to_remove > 0) {
# Selecteer willekeurig de indices die we naar NA gaan zetten
indices_to_remove <- sample(indices_present, size = n_to_remove)
# Zet de geselecteerde waarden op NA
data_missing[[col_name]][indices_to_remove] <- NA
}
}
# Toon een overzicht van de ontbrekende data na de verwijdering
cat("Overzicht van ontbrekende waarden (NAs) per kolom na verwijdering:\n")
print(sapply(data_missing, function(x) sum(is.na(x))))
cat("\nTotaal percentage ontbrekende cellen in de dataset:",
round(sum(is.na(data_missing)) / (nrow(data_missing) * ncol(data_missing)) * 100, 2), "%\n")
# 'm=50' means we create 50 versions of the completed dataset.
# 'pmm' (Predictive Mean Matching) is a good general-purpose imputation method.
# We set printFlag = FALSE to keep the output clean.
imputed_data <- mice(data_missing, m = 100, method = 'pmm', printFlag = FALSE)
# The 'imputed_data' object holds all 50 imputed datasets.
# print(imputed_data)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# We will create a vector to store the sum from each of the 50 datasets.
list_of_sums <- vector("numeric", length = imputed_data$m)
for (i in 1:imputed_data$m) {
# Get the i-th complete dataset
completed_df <- complete(imputed_data, i)
# Calculate the sum of Ozone and store it
list_of_sums[i] <- sum(completed_df$Ozone)
}
# 'list_of_sums' now contains 50 different possible total Ozone values.
# This vector represents the probability distribution of our desired total.
cat("Here are the first 6 calculated sums:\n")
head(list_of_sums)
# The best point estimate for the sum is the average of all the sums.
final_point_estimate <- mean(list_of_sums)
# The uncertainty is captured by the standard deviation of these sums.
uncertainty_std_dev <- sd(list_of_sums)
# We create a 95% confidence interval using the quantiles of our distribution.
confidence_interval <- quantile(list_of_sums, probs = c(0.025, 0.975))
# Print the final results
cat("--- Final Results ---\n")
cat("Point Estimate for Total Ozone:", round(final_point_estimate, 2), "\n")
cat("Uncertainty (Standard Deviation of Sums):", round(uncertainty_std_dev, 2), "\n")
cat("95% Confidence Interval for Total Ozone: [",
round(confidence_interval[1], 2), ", ",
round(confidence_interval[2], 2), "]\n")
# Visualize the distribution of the sums.
hist(list_of_sums,
breaks = 15,
main = "Distribution of possible total ozone sums\nacross 100 imputations",
xlab = "Calculated sum of ozone",
col = "lightblue",
border = "white")
# Add lines for the mean and confidence interval
abline(v = final_point_estimate, col = "red", lwd = 3)
abline(v = confidence_interval, col = "blue", lty = 2, lwd = 2)
abline(v = true_sum_of_Ozone, col = "black", lty = 2, lwd = 2)
legend("topright",
legend = c("Mean estimate", "95% CI", "True sum"),
col = c("red", "blue", "black"),
lty = c(1, 2),
lwd = 2,
bty = "n") # no box around legend
